{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rich\n",
    "from rich.pretty import Pretty\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from modules.data.processeddatainstance import ProcessedDataInstance\n",
    "from modules.dl.tester.utils import confusion_matrix_with_class\n",
    "from modules.shared.config import load_config\n",
    "from modules.shared.utils import get_repo_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook name\n",
    "notebook_name = Path(\"3.a.ml_single_cellfeat.ipynb\").stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "config = load_config(\"ml_analysis.toml\")\n",
    "palmskin_result_name: Path = Path(config[\"data_processed\"][\"palmskin_result_name\"])\n",
    "cluster_desc: str = config[\"data_processed\"][\"cluster_desc\"]\n",
    "dark: int = config[\"SLIC\"][\"dark\"]\n",
    "rich.print(\"\", Pretty(config, expand_all=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_di = ProcessedDataInstance()\n",
    "processed_di.parse_config(\"ml_analysis.toml\")\n",
    "\n",
    "# src\n",
    "repo_root = get_repo_root()\n",
    "slic_dirname = f\"{palmskin_result_name.stem}_{{dark_{dark}}}\"\n",
    "ml_csv = repo_root.joinpath(\"data/generated/ML\", processed_di.instance_name,\n",
    "                            cluster_desc, slic_dirname, \"ml_dataset.csv\")\n",
    "\n",
    "# dst\n",
    "dst_dir = ml_csv.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ml_csv, encoding='utf_8_sig')\n",
    "print(f\"Read ML Dataset: '{ml_csv}'\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(Counter(df[\"class\"]).keys())\n",
    "label2idx = {label: idx for idx, label in enumerate(labels)}\n",
    "rich.print(f\"labels = {labels}\")\n",
    "rich.print(f\"label2idx = {label2idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = df[(df[\"dataset\"] == \"train\") | (df[\"dataset\"] == \"valid\")]\n",
    "test_df = df[(df[\"dataset\"] == \"test\")]\n",
    "\n",
    "training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"cell_count\"\n",
    "assert feature in df.columns, f\"Feature should be one of followings: {list(df.columns)[3:]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 Random Forest 分類器\n",
    "rand_seed = int(cluster_desc.split(\"_\")[-1].replace(\"RND\", \"\"))\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=rand_seed)\n",
    "\n",
    "input_training = training_df[feature].to_numpy()[:, None]\n",
    "gt_training = [label2idx[c_label] for c_label in training_df[\"class\"]]\n",
    "\n",
    "# 訓練模型\n",
    "random_forest.fit(input_training, gt_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測訓練集\n",
    "pred_train = random_forest.predict(input_training)\n",
    "pred_train = [labels[c_idx] for c_idx in pred_train]\n",
    "\n",
    "gt_train = list(training_df[\"class\"])\n",
    "\n",
    "# reports\n",
    "cls_report = classification_report(y_true=gt_train,\n",
    "                                   y_pred=pred_train, digits=5)\n",
    "_, confusion_matrix = confusion_matrix_with_class(prediction=pred_train,\n",
    "                                                  ground_truth=gt_train)\n",
    "# display report\n",
    "print(\"Classification Report:\\n\\n\", cls_report)\n",
    "print(f\"{confusion_matrix}\\n\")\n",
    "\n",
    "# log file\n",
    "with open(dst_dir.joinpath(f\"{notebook_name}.train.log\"), mode=\"w\") as f_writer:\n",
    "    f_writer.write(\"Classification Report:\\n\\n\")\n",
    "    f_writer.write(f\"{cls_report}\\n\\n\")\n",
    "    f_writer.write(f\"{confusion_matrix}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test = test_df[feature].to_numpy()[:, None]\n",
    "\n",
    "# 預測測試集\n",
    "pred_test = random_forest.predict(input_test)\n",
    "pred_test = [labels[c_idx] for c_idx in pred_test]\n",
    "\n",
    "gt_test = list(test_df[\"class\"])\n",
    "\n",
    "# reports\n",
    "cls_report = classification_report(y_true=gt_test,\n",
    "                                   y_pred=pred_test, digits=5)\n",
    "_, confusion_matrix = confusion_matrix_with_class(prediction=pred_test,\n",
    "                                                  ground_truth=gt_test)\n",
    "# display report\n",
    "print(\"Classification Report:\\n\\n\", cls_report)\n",
    "print(f\"{confusion_matrix}\\n\")\n",
    "\n",
    "# log file\n",
    "with open(dst_dir.joinpath(f\"{notebook_name}.test.log\"), mode=\"w\") as f_writer:\n",
    "    f_writer.write(\"Classification Report:\\n\\n\")\n",
    "    f_writer.write(f\"{cls_report}\\n\\n\")\n",
    "    f_writer.write(f\"{confusion_matrix}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(gt_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zebrafish_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
